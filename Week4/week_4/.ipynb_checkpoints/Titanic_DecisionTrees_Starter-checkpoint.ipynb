{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict survival on the Titanic\n",
    "In this Lab, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "The dataset contains 891 observations of 12 variables:\n",
    "* **PassengerId**: Unique ID for each passenger\n",
    "* **Survived**: Survival (0 = No; 1 = Yes)\n",
    "* **Pclass**: Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
    "* **Name**: Name\n",
    "* **Sex**: Sex\n",
    "* **Age**: Age\n",
    "* **Sibsp**: Number of Siblings/Spouses Aboard\n",
    "* **Parch**: Number of Parents/Children Aboard\n",
    "* **Ticket**: Ticket Number\n",
    "* **Fare**: Passenger Fare\n",
    "* **Cabin**: Cabin\n",
    "* **Embarked** Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic = pd.read_csv(\"titanic.csv\" )\n",
    "titanic.drop('Cabin', axis=1, inplace=True) # Drop this column because it contains a lot of Nan values\n",
    "titanic[\"Age\"].fillna(titanic[\"Age\"].median(),inplace=True)\n",
    "titanic[\"Embarked\"].fillna(\"S\", inplace = True)\n",
    "print ('survival rate =', titanic.Survived.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some of the columns don't have predictive power, so let's specify which ones are included for prediction\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", 'SibSp' ,'Parch', \"Fare\", \"Embarked\"]  \n",
    "# We need now to convert text columns in predictors to numerical ones\n",
    "for col in predictors: # Loop through all columns in predictors\n",
    "    if titanic[col].dtype == 'object':  # check if column's type is object (text)\n",
    "        titanic[col] = pd.Categorical(titanic[col]).codes  # convert text to numerical\n",
    "\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the data into a training set and a testing set\n",
    "from sklearn.cross_validation import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(titanic[predictors], titanic['Survived'], test_size=0.3, random_state=1)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "train_score = clf.score(X_train, y_train)\n",
    "print ('train accuracy =', clf.score(X_train, y_train))\n",
    "\n",
    "from sklearn import cross_validation\n",
    "scores = cross_validation.cross_val_score(clf, titanic[predictors], titanic[\"Survived\"], scoring='accuracy', cv=5)\n",
    "print('cross validation accuracy =', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " # Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with one single tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import from: http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n",
    "# your code here\n",
    "clf_dt = DecisionTreeClassifier(random_state=1)\n",
    "# your code here\n",
    "print ('train accuracy =', # your code here)\n",
    "print ('test accuracy =', # your code here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions are obtained in the same way of Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = # your code here\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_prob = # your code here\n",
    "print (y_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's play around with some of the decision tree's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check the sklearn documentation and change the folowing parametrs: max_depth, min_samples_split, min_samples_leaf \n",
    "clf_dt = DecisionTreeClassifier(random_state=1, # your code here)\n",
    "# your code here\n",
    "print ('train accuracy =', # your code here)\n",
    "\n",
    "# Cross validation\n",
    "scores_dt = # your code here\n",
    "print('cross validation accuracy =', # your code here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the decision tree\n",
    "Set the max_depth parameter in the previous classifier to 3 and leave all the other ones to default values.<br>\n",
    "Open the tree.dot file in a text editor, copy the piece of code and paste it  [ @ webgraphviz.com](http://webgraphviz.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "tree.export_graphviz(clf_dt, out_file='tree.dot')\n",
    "# As a reminder, these are the predicting features in order\n",
    "print (dict(zip(range(len(predictors)),predictors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image should look like the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"DT.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the survival of a female, Pclass 1 or 2, above age 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "passenger1=np.array([# your code here]).reshape(1, -1)\n",
    "print ('proba =', # your code here)\n",
    "print ('class =', # your code here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the survival of a male, above age 11.5, Pclass 2 or 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "passenger2=np.array([# your code here]).reshape(1, -1)\n",
    "print ('proba =', # your code here)\n",
    "print ('class =', # your code here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at this decision tree, you can get a sense the relative importance between features. let's see which are the most important ones using the attribute: **feature\\_importances_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_imp = pd.DataFrame(clf_dt.feature_importances_, predictors, columns=['Importance'])\n",
    "feat_imp.sort_values('Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, **Parch** and **Fare** are the least important ones because they were not used for splitting, while **Sex** is the most important one since it was used first for splitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "A   [Random Forest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier from sklearn.ensemble import RandomForestClassifier) is an ensemble of [decision trees](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import from: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier\n",
    "# your code here\n",
    "clf_rf = RandomForestClassifier(random_state=1)  # by default, 10 trees are used\n",
    "# your code here\n",
    "print ('train accuracy =', # your code here)\n",
    "\n",
    "# Cross validation\n",
    "scores_rf = # your code here\n",
    "print('cross validation accuracy =', # your code here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same way, you can print the feature importance of all the trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest, like decision trees have a lot of parameters to tune. Usually, performance does not change linearly with parameters. Let's take as an example, the accuracy as a function of number of trees (**n_estimators**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "trees=range(50)\n",
    "accuracy=np.zeros(50)\n",
    "for idx in range(len(trees)):\n",
    "    clf_rf=RandomForestClassifier(random_state=1, n_estimators=idx + 1)\n",
    "    clf_rf.fit(X_train,y_train)\n",
    "    accuracy[idx]=clf_rf.score(X_test, y_test)  \n",
    "\n",
    "plt.plot(trees, accuracy)\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('Number of Trees')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, try to tune manually the following parameters: **min_samples_leaf, min_samples_split, max_depth, n_estimators** in order to increase cross validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier(random_state=1, # your code here)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "print ('train accuracy =', clf_rf.score(X_train, y_train))\n",
    "\n",
    "# Cross validation\n",
    "scores_rf = cross_validation.cross_val_score(clf_rf, titanic[predictors], titanic[\"Survived\"], scoring='accuracy', cv=5)\n",
    "print('cross validation accuracy =', scores_rf.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This might be a difficult job to do manually. In other way is to search automatically the best combination of different ranges for these parameters. This is done using **Grid Search**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Documentation: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV\n",
    "# your code here\n",
    "params = {'min_samples_leaf':list(range(1,5)),'min_samples_split':list(range(2,10,2)),\n",
    "          'n_estimators':list(range(10,50,10))}\n",
    "clf_rf2=RandomForestClassifier(random_state=1)\n",
    "clf_gs=GridSearchCV(clf_rf2, params, scoring = 'accuracy',cv=5)\n",
    "clf_gs.fit(titanic[predictors], titanic[\"Survived\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the best score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use these best parameters and check whether they achieve really the above cv accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_rf3 = RandomForestClassifier(random_state=1, # your code here) \n",
    "clf_rf3.fit(X_train, y_train)\n",
    "print ('train accuracy =', clf_rf3.score(X_train, y_train))\n",
    "\n",
    "scores_rf3 = cross_validation.cross_val_score(clf_rf3, titanic[predictors], titanic[\"Survived\"], scoring='accuracy', cv=5)\n",
    "print('cross validation accuracy =',scores_rf3.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As you can see, grid search allows you to find the best model parameters to improve your accuracy. Now, we can see the most important features of this last classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_imp = pd.DataFrame(clf_rf3.feature_importances_, predictors, columns=['Importance'])\n",
    "feat_imp.sort_values('Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
